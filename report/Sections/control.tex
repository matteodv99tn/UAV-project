\section{Control} \label{sec:control}
The control scheme developed is similar to the one proposed in \cite{rospo} that exploits an hierarchical control architecture with an high level controller responsible to convert the system's state and the respective desired motion into a virtual wrench that's desired on the center of mass (com), and an allocator that dispatches the loads into the different turrets to achieve the goal.

\subsection{High level controller}
The high level controller used in this project is the one derived in \cite{rospo} and is developed so that the controller sees an equivalent first-order linear dynamics.

The commanded virtual input $\vett u_{v,c}$, i.e. the desired wrench on the com of the ROSPO, is computed by the law
\begin{equation} \label{eq:virtualinput}
    \vett u_{v,c} = \matt B^{-1} \big( \dvett u_{v}^{\star} - \matt A \vett u_{v}^{\star}\big) - \matt K \tilde{\vett u}_{v}
\end{equation}
with $\matt A = -\gamma_{P} \matt I_{3}$, $\matt B = \gamma_{P} \matt I_{3}$ and $\matt K\in \mathbb R^{3\times 3}$ a gain matrix such that $\matt A - \matt{BK}$ is Hurwitz. In (\ref{eq:virtualinput}) the feedforward signal and it's time derivative are
\begin{align*}
\vett u_{v}^{\star} & = \begin{pmatrix}
    m \matt R^{\top}(\psi) \left( -k_{p} \tilde{\vett p} - k_{d}\dot{\tilde{\vett p}} + \ddvett p_{ref} - \frac{\vett F_{f}(\vett x)}{m} \right) \\
    J \left( -k_{p, \psi} \tilde{\psi} - k_{d,\psi}\dot{\tilde{\psi}} + \ddot \psi_{ref} - \frac{T_{f,\psi}(\vett x)}{J} \right)
\end{pmatrix} \\
\dvett u_{v}^{\star} & = \begin{pmatrix}
    m \matt R^{\top}(\psi) \big( \matt S(\psi) \vett v + \vett v_{d} \big) \\
    J \left( -k_{p, \psi} \dot{\tilde{\psi}} - k_{d,\psi}\ddot{\tilde{\psi}} + \dddot \psi_{ref} - \frac{\dot T_{f,\psi}(\vett x)}{J} \right)
\end{pmatrix}
\end{align*}
with $k_{\circ}$ all positive gains, $\vett F_{f}, T_{f,\psi}$ respectively the force and the torque due to the friction (as function of the current state of the ROSPO), and $\tilde{\vett p} = \vett p - \vett p_{ref}$ the position error w.r.t. the reference trajectory described by $\vett p_{ref}$. Finally
\begin{align*}
\matt S(\psi) & = \begin{bmatrix}
    0 & \dot \psi \\ -\dot \psi & 0
\end{bmatrix} \\
    \vett v & = -k_{p} \tilde{\vett p} - k_{d} \dot{\tilde{\vett p}} + \ddvett p_{ref} - \frac{\vett F_{f}}{m} \\
    \vett v_{d} & = -k_{p} \dot{\tilde{\vett p}} - k_{d} \ddot{\tilde{\vett p}} + \dddot{\vett p}_{ref} - \frac{\dvett F_{f}}{m}
\end{align*}


\subsection{Allocator}
Most of the effort for the project has been put into the development of the allocator whose goal is to convert the commanded virtual input $\vett u_{v,c}$ into a set of proper inputs $\vett u$ for the system.

In the reference paper, such task is accomplished exploiting the system's model by using an input that guarantees an optimal regulation as well as asymptotic optimality condition; due to the nature of such problem, no saturation or boundaries on the inputs can be ensured, but they are regarded as soft constraints by properly choosing the cost function.

The idea that I propose is instead to use deep neural networks to approximate the optimal input allocation; based on the system's model, a dataset of optimal allocations can be computed offline and used to train the neural network that later can be used only in prediction while running on the effective system. \\
With this approach computationally expensive algorithms can be used offline to accomplish the allocation while at runtime a deterministic computation of the input is guaranteed by the evaluation of the neural network.

The developed allocation method relies on 2 stages that exploits different neural networks: the first one performs the proper allocation by computing the force (with its attitude) that each turret should have at the next controller update (based on the current state and the commanded virtual input) and a lower-level controller that converts the desired force into a voltage to be applied at the BLDC motors. For sake of simplicity the latter one is described first. \vspace{3mm}

\subsubsection{BLDC voltage identification}
To compute the voltage $v$ that allows to reach a desired force $F_{des}$, model (\ref{eq:motordynamics}) is used.

Since $v$ doesn't appear explicitly in (\ref{eq:motorforce}), the force $F$ generated by the model can't be instaneously changed by choosing the voltage; for this reason a discrete approach has been used: given the initial state $\vett x_{0} \in \mathbb R^{2}$ of the motor, the ODE is numerically integrated using Runge Kutta methods to determine the force $F^{+}$ at the next cycle of the controller. With this idea the optimal control $v^{\star}$ is given by
\begin{equation} \label{eq:optimalvoltage}
    v^{\star}(\vett x_{0}) = \arg \min_{v} \big\|F^{+}(v, \vett x_{0}) - F_{des}\big\|^{2}
\end{equation}

To improve the convergence of numerical methods, the explicit definition of the jacobian of the cost w.r.t. the decision variable $v$ has been provided; rewriting in fact the cost as
\[ c = \big(F^{+} - F_{des}\big)^{\top} \big(F^{+} - F_{des}\big)\]
it turns out that
\[ \diff c v = 2 \big(F^{+} - F_{des}\big) \pdiff{F}{\vett x} \diff{\vett x}v \]
where $\diff{\vett x}v$ can be obtain by computing the sensitivities with the Runge Kutta methods.

The dataset for computing the input voltage to the motor has been generated from solving (\ref{eq:optimalvoltage}) by uniformly sampling $\vett x_{0} \in \mathcal X \subset \mathbb R^{2}$ on a set of bounded values for the state and constraining $v\in [0,v_{max}]$. \\
To increase the quality of the dataset, data have been generated also considering $\vett x_{0}$ as a small deviation from a steady-state configuration.
\vspace{3mm}

\subsubsection{Allocation}
The dataset for the allocator neural-network has been developed similarly to the previous case, i.e. by solving constrained least-square problems on state uniformly sampled from a defined subspace.

For this problem let's consider the state $\vett x \in \mathbb R^{2N_{t}}$ the one defined as
\[ \vett x = \Big( F_{1}, \phi_{1}, \dots, F_{N_{t}}, \phi_{N_{t}}\Big)^{\top} \]
while $\vett u \in \mathbb R^{2N_{t}}$ is simply the ratio of change in time of the respective variables, i.e.
\[ \vett u = \Big( \delta F_{1}, \delta\phi_{1}, \dots, \delta F_{N_{t}}, \delta\phi_{N_{t}}\Big)^{\top} \]

Defined with $\vett F_{com}(\vett x): \ \mathbb R^{2N_{t}} \rightarrow \mathbb R^{3}$\footnote{In this case we implicitly assume that the force is a 3-dimensional vector with the 3rd component being the applied torque.} the function that given the current state provides the wrench applied to the com, then the minimization problem to solve is of the form
\begin{equation} \label{eq:allocproblem}
\begin{aligned}
    \vett u^{\star} (\vett x_{0}) = \arg \min_{\vett u} & \big\|\vett F_{com}(\vett x_{0} + T_{s}\vett u) - \vett F_{des} \big\|^{2}_{\matt W_{1}} \\ & + k \| \vett u \|^{2}_{\matt W_{2}}
\end{aligned}
\end{equation}
The reported cost function have 2 main contributions: the first one is used to regulate the input toward the desired wrench, while the second one minimizes the actuation effort. In both cases the least-square costs are weighted by matrices $\matt W_{\circ}$ in order to improve the control selection.

Also in this case a subset for both $\vett F_{des}$ and $\vett x_{0}$ is defined; the dataset is built by randomly sampling from those spaces and solving problem (\ref{eq:allocproblem}) considering boundaries on $\vett u$.
